{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ranger: A Fast Implementation of Random Forests</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(mlr)\n",
    "library(parallel)\n",
    "source('../utils.r')\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "data_folder_name  = '../../raw_data'\n",
    "data_file_name    = 'airfoil_self_noise.dat'\n",
    "model_folder_name = '../model'\n",
    "model_file_name   = 'model_regr_ranger.RData'\n",
    "ml_algorithm      = \"regr.ranger\"\n",
    "gs_max_iteration  = 10\n",
    "gs_max_time       = 5#60#*60*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = read_data(data_folder_name %+/% data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRow: 1503\n",
      "NCol: 6"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 800      </td><td>0         </td><td>0.3048    </td><td>71.3      </td><td>0.00266337</td><td>126.201   </td></tr>\n",
       "\t<tr><td>1000      </td><td>0         </td><td>0.3048    </td><td>71.3      </td><td>0.00266337</td><td>125.201   </td></tr>\n",
       "\t<tr><td>1250      </td><td>0         </td><td>0.3048    </td><td>71.3      </td><td>0.00266337</td><td>125.951   </td></tr>\n",
       "\t<tr><td>1600      </td><td>0         </td><td>0.3048    </td><td>71.3      </td><td>0.00266337</td><td>127.591   </td></tr>\n",
       "\t<tr><td>2000      </td><td>0         </td><td>0.3048    </td><td>71.3      </td><td>0.00266337</td><td>127.461   </td></tr>\n",
       "\t<tr><td>2500      </td><td>0         </td><td>0.3048    </td><td>71.3      </td><td>0.00266337</td><td>125.571   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " V1 & V2 & V3 & V4 & V5 & V6\\\\\n",
       "\\hline\n",
       "\t  800       & 0          & 0.3048     & 71.3       & 0.00266337 & 126.201   \\\\\n",
       "\t 1000       & 0          & 0.3048     & 71.3       & 0.00266337 & 125.201   \\\\\n",
       "\t 1250       & 0          & 0.3048     & 71.3       & 0.00266337 & 125.951   \\\\\n",
       "\t 1600       & 0          & 0.3048     & 71.3       & 0.00266337 & 127.591   \\\\\n",
       "\t 2000       & 0          & 0.3048     & 71.3       & 0.00266337 & 127.461   \\\\\n",
       "\t 2500       & 0          & 0.3048     & 71.3       & 0.00266337 & 125.571   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "V1 | V2 | V3 | V4 | V5 | V6 | \n",
       "|---|---|---|---|---|---|\n",
       "|  800       | 0          | 0.3048     | 71.3       | 0.00266337 | 126.201    | \n",
       "| 1000       | 0          | 0.3048     | 71.3       | 0.00266337 | 125.201    | \n",
       "| 1250       | 0          | 0.3048     | 71.3       | 0.00266337 | 125.951    | \n",
       "| 1600       | 0          | 0.3048     | 71.3       | 0.00266337 | 127.591    | \n",
       "| 2000       | 0          | 0.3048     | 71.3       | 0.00266337 | 127.461    | \n",
       "| 2500       | 0          | 0.3048     | 71.3       | 0.00266337 | 125.571    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  V1   V2 V3     V4   V5         V6     \n",
       "1  800 0  0.3048 71.3 0.00266337 126.201\n",
       "2 1000 0  0.3048 71.3 0.00266337 125.201\n",
       "3 1250 0  0.3048 71.3 0.00266337 125.951\n",
       "4 1600 0  0.3048 71.3 0.00266337 127.591\n",
       "5 2000 0  0.3048 71.3 0.00266337 127.461\n",
       "6 2500 0  0.3048 71.3 0.00266337 125.571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat(sprintf('NRow: %d\\nNCol: %d',nrow(data), ncol(data)))\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assunming that target is the last column of the data. \n",
    "If it's not true, one most declare the name of the column that represents the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = names(data)[ncol(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRow: 1503\n",
      "NCol: 6"
     ]
    }
   ],
   "source": [
    "drops = c()\n",
    "data  = data[,c(!(names(data) %in% drops)), with=FALSE]\n",
    "cat(sprintf('NRow: %d\\nNCol: %d',nrow(data), ncol(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Make Task</h2><br>\n",
    "\n",
    "The task encapsulates the data and specifies - through its subclasses - the type of the task. It also contains a description object detailing further aspects of the data. Useful operators are: getTaskFormula, getTaskFeatureNames, getTaskData, getTaskTargets, and subsetTask.\n",
    "\n",
    "Function\n",
    "```R\n",
    "makeRegrTask(id = deparse(substitute(data)), data, target, weights = NULL, blocking = NULL, \n",
    "             fixup.data = \"warn\", check.data = TRUE)\n",
    "```\n",
    "Param.:\n",
    "\n",
    "* data: [data.frame] A data frame containing the features and target variable(s).\n",
    "* target: [character(1)] Name of the target variable.\n",
    "* weights: [numeric] Optional, non-negative case weight vector to be used during fitting. Cannot be set for cost-sensitive learning. Default is NULL which means no (= equal) weights.\n",
    "* fixup.data: [character(1)] Should some basic cleaning up of data be performed? Currently this means removing empty factor levels for the columns. Possible coices are: “no” = Don't do it. “warn” = Do it but warn about it. “quiet” = Do it but keep silent. Default is “warn”.\n",
    "\n",
    "Doc.: https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/makeRegrTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in makeTask(type = type, data = data, weights = weights, blocking = blocking, :\n",
      "“Provided data is not a pure data.frame but from class data.table, hence it will be converted.”"
     ]
    }
   ],
   "source": [
    "task = makeRegrTask(data=data, target = target, fixup.data = 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Make Learner</h2><br>\n",
    "Function\n",
    "```R\n",
    "makeLearner(cl, id = cl, predict.type = \"response\", predict.threshold = NULL, \n",
    "            fix.factors.prediction = FALSE, ..., par.vals = list(), config = list())\n",
    "```\n",
    "Param.:\n",
    "\n",
    "* cl: [character(1)] Class of learner. By convention, all regression learners with “regr.”. A list of all integrated learners is available on the learners help page < https://mlr-org.github.io/mlr-tutorial/release/html/integrated_learners/ >.\n",
    "* predict: [character(1)] “response” (= mean response) or “se” (= standard errors and mean response). Default is “response”.\n",
    "* par.vals: [list] Optional list of named (hyper)parameters. The arguments in ... take precedence over values in this list. We strongly encourage you to use one or the other to pass (hyper)parameters to the learner but not both.\n",
    "\n",
    "Doc.: https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/makeLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learner = makeLearner(cl = ml_algorithm, par.vals=list(verbose=FALSE,num.threads=1,seed=42, importance='impurity'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Specifying the search space</h2><br>\n",
    "\n",
    "In order to define a search space, we create a ParamSet object, which describes the parameter space we wish to search. This is done via the function makeParamSet. For each parameter type a special constructor function is available, see: https://www.rdocumentation.org/packages/ParamHelpers/versions/1.10/topics/Param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                      Type  len      Def\n",
       "num.trees                          integer    -      500\n",
       "mtry                               integer    -        -\n",
       "min.node.size                      integer    -        5\n",
       "replace                            logical    -     TRUE\n",
       "sample.fraction                    numeric    -        -\n",
       "split.select.weights         numericvector <NA>        -\n",
       "always.split.variables             untyped    -        -\n",
       "respect.unordered.factors          logical    -    FALSE\n",
       "importance                        discrete    -     none\n",
       "write.forest                       logical    -     TRUE\n",
       "scale.permutation.importance       logical    -    FALSE\n",
       "num.threads                        integer    -        -\n",
       "save.memory                        logical    -    FALSE\n",
       "verbose                            logical    -     TRUE\n",
       "seed                               integer    -        -\n",
       "splitrule                         discrete    - variance\n",
       "alpha                              numeric    -      0.5\n",
       "minprop                            numeric    -      0.1\n",
       "keep.inbag                         logical    -    FALSE\n",
       "                                                Constr Req Tunable Trafo\n",
       "num.trees                                     1 to Inf   -    TRUE     -\n",
       "mtry                                          1 to Inf   -    TRUE     -\n",
       "min.node.size                                 1 to Inf   -    TRUE     -\n",
       "replace                                              -   -    TRUE     -\n",
       "sample.fraction                                 0 to 1   -    TRUE     -\n",
       "split.select.weights                            0 to 1   -    TRUE     -\n",
       "always.split.variables                               -   -    TRUE     -\n",
       "respect.unordered.factors                            -   -    TRUE     -\n",
       "importance                   none,impurity,permutation   -   FALSE     -\n",
       "write.forest                                         -   -   FALSE     -\n",
       "scale.permutation.importance                         -   Y   FALSE     -\n",
       "num.threads                                   1 to Inf   -   FALSE     -\n",
       "save.memory                                          -   -   FALSE     -\n",
       "verbose                                              -   -   FALSE     -\n",
       "seed                                       -Inf to Inf   -   FALSE     -\n",
       "splitrule                             variance,maxstat   -    TRUE     -\n",
       "alpha                                           0 to 1   Y    TRUE     -\n",
       "minprop                                         0 to 1   Y    TRUE     -\n",
       "keep.inbag                                           -   -   FALSE     -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getParamSet(ml_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_set = makeParamSet(\n",
    "  makeIntegerParam(\"num.trees\", lower = 100, upper = 3000),\n",
    "  makeIntegerParam(\"mtry\",      lower = 2,   upper = ceiling(sqrt(length(getTaskFeatureNames(task))))),  \n",
    "  makeIntegerParam('min.node.size', lower = 5,   upper = 50)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Specifying the optimization algorithm</h2><br>\n",
    "\n",
    "Once we have specified the search space, we need to choose an optimization algorithm for our parameters. Optimization algorithms are considered TuneControl objects in mlr. The following tuners are available: https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/TuneControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimization_algorithm = makeTuneControlGenSA(max.call=gs_max_iteration, max.time=gs_max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resampling strategy</h2><br>\n",
    "\n",
    "Function:\n",
    "```R\n",
    "makeResampleDesc(method, predict = \"test\", ..., stratify = FALSE, stratify.cols = NULL)\n",
    "```\n",
    "Param.:\n",
    "\n",
    "* method: [character(1)] “CV” for cross-validation, “LOO” for leave-one-out, “RepCV” for repeated cross-validation, “Bootstrap” for out-of-bag bootstrap, “Subsample” for subsampling, “Holdout” for holdout.\n",
    "* predict: What to predict during resampling: “train”, “test” or “both” sets. Default is “test”.\n",
    "* ... : [any] Further parameters for strategies.\n",
    "    * iters [integer(1)] Number of iterations, for “CV”, “Subsample” and “Boostrap”.\n",
    "    * split [numeric(1)] Proportion of training cases for “Holdout” and “Subsample” between 0 and 1. Default is 2/3.\n",
    "    * reps [integer(1)] Repeats for “RepCV”. Here iters = folds * reps. Default is 10.\n",
    "    * folds [integer(1)] Folds in the repeated CV for RepCV. Here iters = folds * reps. Default is 10.\n",
    "\n",
    "Doc.: https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/makeResampleDesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resample = makeResampleDesc(method = \"CV\", iters = 3, predict = 'both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Measures</h2><br>\n",
    "\n",
    "List of performance measures:\n",
    "\n",
    "Doc.: http://mlr-org.github.io/mlr-tutorial/release/html/measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures = list(mae, rmse, expvar, timetrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Performing the tuning</h2><br>\n",
    "\n",
    "Optimizes the hyperparameters of a learner. Allows for different optimization methods, such as grid search, evolutionary strategies, iterated F-race, etc. You can select such an algorithm (and its settings) by passing a corresponding control object. For a complete list of implemented algorithms look at TuneControl. Multi-criteria tuning can be done with tuneParamsMultiCrit.\n",
    "\n",
    "Function:\n",
    "```R\n",
    "tuneParams(learner, task, resampling, measures, par.set, control, show.info = getMlrOption(\"show.info\"))\n",
    "```\n",
    "Param.:\n",
    "\n",
    "* learner: [Learner | character(1)] The learner. If you pass a string the learner will be created via makeLearner\n",
    "* task: [Task] The task.\n",
    "* resampling: [ResampleInstance | ResampleDesc] Resampling strategy to evaluate points in hyperparameter space.\n",
    "* measures: [list of Measure | Measure] Performance measures to evaluate. The first measure, aggregated by the first aggregation function is optimized, others are simply evaluated. \n",
    "* par.set: [ParamSet] Collection of parameters and their constraints for optimization. Dependent parameters with a requires field must use quote and not expression to define it.\n",
    "* control: [TuneControl] Control object for search method. Also selects the optimization algorithm for tuning.\n",
    "* show.info: [logical(1)] Print verbose output on console? Default is set via configureMlr.\n",
    "\n",
    "Doc.: https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/tuneParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cpus = detectCores(all.tests = FALSE, logical = TRUE) - 1\n",
    "parallelMap::parallelStartMulticore(cpus, show.info=FALSE)\n",
    "\n",
    "tune_result = tuneParams(learner, task, resample, measures, param_set, optimization_algorithm, show.info=FALSE)\n",
    "\n",
    "parallelMap::parallelStop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>mae.test.mean</dt>\n",
       "\t\t<dd>1.65537951983968</dd>\n",
       "\t<dt>rmse.test.rmse</dt>\n",
       "\t\t<dd>2.23624589318838</dd>\n",
       "\t<dt>expvar.test.mean</dt>\n",
       "\t\t<dd>0.731872918582259</dd>\n",
       "\t<dt>timetrain.test.mean</dt>\n",
       "\t\t<dd>6.25666666666651</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mae.test.mean] 1.65537951983968\n",
       "\\item[rmse.test.rmse] 2.23624589318838\n",
       "\\item[expvar.test.mean] 0.731872918582259\n",
       "\\item[timetrain.test.mean] 6.25666666666651\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mae.test.mean\n",
       ":   1.65537951983968rmse.test.rmse\n",
       ":   2.23624589318838expvar.test.mean\n",
       ":   0.731872918582259timetrain.test.mean\n",
       ":   6.25666666666651\n",
       "\n"
      ],
      "text/plain": [
       "      mae.test.mean      rmse.test.rmse    expvar.test.mean timetrain.test.mean \n",
       "          1.6553795           2.2362459           0.7318729           6.2566667 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune_result$y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>num.trees</dt>\n",
       "\t\t<dd>2811</dd>\n",
       "\t<dt>mtry</dt>\n",
       "\t\t<dd>3</dd>\n",
       "\t<dt>min.node.size</dt>\n",
       "\t\t<dd>7</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[num.trees] 2811\n",
       "\\item[mtry] 3\n",
       "\\item[min.node.size] 7\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "num.trees\n",
       ":   2811mtry\n",
       ":   3min.node.size\n",
       ":   7\n",
       "\n"
      ],
      "text/plain": [
       "    num.trees          mtry min.node.size \n",
       "         2811             3             7 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unlist(tune_result$x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train A Learning Algorithm with best Hyperparameters</h2><br>\n",
    "\n",
    "Given a Task, creates a model for the learning machine which can be used for predictions on new data.\n",
    "\n",
    "Function:\n",
    "```R\n",
    "train(learner, task, subset, weights = NULL)\n",
    "```\n",
    "Param.:\n",
    "\n",
    "* learner: [Learner | character(1)] The learner. If you pass a string the learner will be created via makeLearner.\n",
    "* task: [Task] The task.\n",
    "* subset: [integer | logical] Selected cases. Either a logical or an index vector. By default all observations are used.\n",
    "* weights: [numeric] Optional, non-negative case weight vector to be used during fitting. If given, must be of same length as subset and in corresponding order. By default NULL which means no weights are used unless specified in the task (Task). Weights from the task will be overwritten.\n",
    "\n",
    "Doc.: https://www.rdocumentation.org/packages/mlr/versions/2.10/topics/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_learner = setHyperPars(tune_result$learner, par.vals = tune_result$x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with all data to make final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = train(optimal_learner, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculates Feature Importance Values For Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureImportance:\n",
       "Task: data\n",
       "\n",
       "Learner: regr.ranger\n",
       "Measure: NA\n",
       "Contrast: NA\n",
       "Aggregation: function (x)  x\n",
       "Replace: NA\n",
       "Number of Monte-Carlo iterations: NA\n",
       "Local: FALSE\n",
       "       V1       V2       V3      V4       V5\n",
       "1 29081.2 5862.249 8224.299 2885.39 21566.24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getFeatureImportance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59630992 bytes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object.size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for learner.id=regr.ranger; learner.class=regr.ranger\n",
      "Trained on: task.id = data; obs = 1503; features = 5\n",
      "Hyperparameters: num.threads=1,verbose=FALSE,respect.unordered.factors=TRUE,seed=42,importance=impurity,num.trees=2811,mtry=3,min.node.size=7\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save final model</h2><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save(model, file = model_folder_name %+/% model_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
